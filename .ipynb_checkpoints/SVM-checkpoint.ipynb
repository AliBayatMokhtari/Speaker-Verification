{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import python_speech_features\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading files in the direction with the specific name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(direction, name=''):\n",
    "    if not os.path.exists(direction):\n",
    "        raise 'Directory is not available'\n",
    "    files = '{}/{}*.wav'.format(direction, name)\n",
    "    return glob(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```extract()``` extracts Mel Frequency Cepsteral Coefficients (MFCC) features from a single file.\n",
    "\n",
    "```batch_extract()``` extracts all MFCC features from training files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(audio):\n",
    "    SAMPLE_RATE = 11025\n",
    "    FRAME_LENGTH = int(SAMPLE_RATE * 0.025)\n",
    "    FRAME_STEP = FRAME_LENGTH - int(SAMPLE_RATE * 0.015)\n",
    "    PRE_EMPH = 0.97\n",
    "    WINDOW_LENGTH = 0.025\n",
    "    WINDOW_STEP = 0.010\n",
    "    WINDOW_FUNCTION = np.hamming\n",
    "    f = []\n",
    "    \n",
    "    def calculate_all(feats):\n",
    "            f.extend(feats.min(axis=0))\n",
    "            f.extend(feats.max(axis=0))\n",
    "            f.extend(feats.mean(axis=0))\n",
    "            f.extend(feats.var(axis=0))\n",
    "    \n",
    "    def calculate_energy(frames):\n",
    "        energies = []\n",
    "        for frame in frames:\n",
    "            energy = 1 / len(frame) * np.sum(np.power(frame, 2))\n",
    "            energies.append(energy)\n",
    "        return energies\n",
    "    \n",
    "    def calculate_zcr(frames):\n",
    "        def sign(x):\n",
    "            return 1 if x >= 0 else -1\n",
    "        \n",
    "        zc_rates = []\n",
    "        for frame in frames:\n",
    "            zc_rate = 0\n",
    "            for i in range(1, len(frame)):\n",
    "                zc_rate += abs(sign(frame[i]) - sign(frame[i - 1])) / 2\n",
    "            zc_rates.append(zc_rate / len(frame))\n",
    "        return zc_rates\n",
    "    \n",
    "    rate, signal = wavfile.read(audio)\n",
    "    signal_frames = python_speech_features.sigproc.framesig(signal, frame_len=FRAME_LENGTH,\n",
    "                                                            frame_step=FRAME_STEP,\n",
    "                                                            winfunc=WINDOW_FUNCTION)\n",
    "    mfcc = python_speech_features.mfcc(signal_frames, rate, winlen=WINDOW_LENGTH,\n",
    "                                      winstep=WINDOW_STEP, numcep=13, preemph=PRE_EMPH,\n",
    "                                      winfunc=WINDOW_FUNCTION)\n",
    "    delta = np.concatenate([np.zeros(shape=(1, 13)), np.diff(mfcc, n=1, axis=0)])\n",
    "    delta_delta = np.concatenate([np.zeros(shape=(2, 13)), np.diff(mfcc, n=2, axis=0)])\n",
    "    \n",
    "    calculate_all(mfcc)\n",
    "    calculate_all(delta)\n",
    "    calculate_all(delta_delta)\n",
    "    \n",
    "    energies = calculate_energy(signal_frames)\n",
    "    calculate_all(np.array([energies]).reshape(len(energies), 1))\n",
    "    \n",
    "    zcrs = calculate_zcr(signal_frames)\n",
    "    calculate_all(np.array([zcrs]).reshape(len(zcrs), 1))\n",
    "    \n",
    "    return np.asarray(f)\n",
    "\n",
    "def batch_extract(direction):\n",
    "    feats, labels = [], []\n",
    "    \n",
    "    valid_samples = read_files(direction, name='ABM')\n",
    "    for sample in valid_samples:\n",
    "        sample_feats = extract(sample)\n",
    "        feats.append(sample_feats)\n",
    "        labels.append(1)\n",
    "    \n",
    "    invalid_samples = read_files(direction, name='NABM')\n",
    "    for sample in invalid_samples:\n",
    "        sample_feats = extract(sample)\n",
    "        feats.append(sample_feats)\n",
    "        labels.append(-1)\n",
    "    \n",
    "    return np.asarray(feats), np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```record()``` records a single voice from the user.\n",
    "\n",
    "```batch_record()``` records bunch of voices from the user inorder to record training files or test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(samplerate=11025, duration=2, play_rec=False, flag='test'):\n",
    "    FRAMES = int(duration * samplerate)\n",
    "    print('Recording Started')\n",
    "    voice = sd.rec(FRAMES, samplerate, dtype=np.float, channels=1, mapping=None, blocking=True)\n",
    "    print('Recording Ended')\n",
    "    \n",
    "    if play_rec is True:\n",
    "        sd.play(voice, samplerate, blocking=True)\n",
    "    \n",
    "    if flag == 'test':\n",
    "        wavfile.write(filename='temp.wav', rate=samplerate, data=voice)\n",
    "        time.sleep(1)\n",
    "    elif flag == 'train':\n",
    "        return voice, samplerate\n",
    "    \n",
    "def batch_record(direction, count, name):\n",
    "    if not os.path.exists(direction):\n",
    "        os.makedirs(direction)\n",
    "    \n",
    "    last_file = len(read_files(direction, name))\n",
    "    for cnt in range(last_file, last_file + count):\n",
    "        file_name = '{}/{}.wav'.format(direction, name + str(cnt))\n",
    "        voice, samplerate = record(flag='train')\n",
    "        wavfile.write(filename, samplerate, data=voice)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```create_classifier()``` creates a classifier, fit it with the features and labels returned from ```batch_extract()```. finally save the classifier in a python object. \n",
    "\n",
    "```predict()``` if the test file is verified it returns ```1``` else returns ```-1```.\n",
    "\n",
    "```single_test()``` records a voice from user and says that the person is verified or not.\n",
    "\n",
    "```calculate_accuracy()``` predicts all the test files in the directory and returns the accuracy of classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(feats, labels, pca_flag=False):\n",
    "    clf = SVC(C=1, max_iter=-1, gamma='auto')\n",
    "    if pca_flag is True:\n",
    "        pca = joblib.load('pca.pkl')\n",
    "        feats = pca.transform(feats)\n",
    "    \n",
    "    clf.fit(feats, labels)\n",
    "    joblib.dump(clf, filename='SVM.pkl')\n",
    "    time.sleep(1)\n",
    "    \n",
    "def predict(clf, audio, pca_flag=False):\n",
    "    feats = extract(audio)\n",
    "    if pca_flag is True:\n",
    "        pca = joblib.load('pca.pkl')\n",
    "        feats = pca.transform(feats.reshape(1, -1))\n",
    "    ans = clf.predict(feats.reshape(1, -1))\n",
    "    if ans == 1:\n",
    "        print('\\n\\nAli Bayat Mokhtari Verified')\n",
    "    else:\n",
    "        print('\\n\\nNot Verified!')\n",
    "\n",
    "    return ans\n",
    "\n",
    "def single_test():\n",
    "    record(play_rec=True)\n",
    "    clf = joblib.load('SVM.pkl')\n",
    "    res = predict(clf, 'temp.wav', pca_flag=True)\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "def calculate_accuracy(direction, name):\n",
    "    corrects = 0\n",
    "    clf.load('SVM.pkl')\n",
    "    test_files = read_files(direction, name)\n",
    "    for test_file in test_files:\n",
    "        ans = predict(clf, audio=test_file, pca_flag=True)\n",
    "        if ans == -1:\n",
    "            corrects += 1\n",
    "    \n",
    "    print((corrects / len(test_files)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```create_pca()``` fits a pca model to reduce dimentions from features inorder to get better accuracy. Also saves it in a python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pca(feats, n_feats):\n",
    "    pca = PCA(n_components=n_feats, whiten=True)\n",
    "    pca.fit(feats)\n",
    "    joblib.dump(pca, filename='pca.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main region of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 164)\n"
     ]
    }
   ],
   "source": [
    "feats, labels = batch_extract(direction='./train')\n",
    "create_pca(feats, n_feats=40)\n",
    "create_classifier(feats, labels, pca_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording Started\n",
      "Recording Ended\n",
      "\n",
      "\n",
      "Ali Bayat Mokhtari Verified\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "ans = single_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
